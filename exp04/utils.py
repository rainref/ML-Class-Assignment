import os
import sys

import matplotlib.pyplot as plt
import numpy as np
import torch
import torch_fidelity
from torchvision.utils import save_image


def sample_images(epoch, generator, num_classes, device, results_path, z_dim):
    """æŒ‰ç±»åˆ«ä¿å­˜ç”Ÿæˆçš„å›¾ç‰‡"""
    generator.eval()
    with torch.no_grad():
        # æ¯ä¸ªç±»åˆ«ç”Ÿæˆ 8 å¼ 
        n_row = 10
        # æ„é€ æ ‡ç­¾: 0~9 æ¯ä¸ªé‡å¤ 8 æ¬¡
        labels = torch.LongTensor(np.array([num for num in range(num_classes) for _ in range(n_row)])).to(
            device)
        z = torch.randn(num_classes * n_row, z_dim).to(device)

        gen_imgs = generator(z, labels)

        # å› ä¸ºç”ŸæˆèŒƒå›´æ˜¯ [-1, 1]ï¼Œä¿å­˜å‰éœ€è¦åå½’ä¸€åŒ–åˆ° [0, 1]
        # (img + 1) / 2
        save_image(gen_imgs.data, os.path.join(results_path, f"epoch_{epoch}.png"), nrow=n_row, normalize=True)
    generator.train()


def plot_loss_curve(loss_values, pic_path):
    """
    ç®€åŒ–ç‰ˆæŸå¤±æ›²çº¿ç»˜åˆ¶å‡½æ•°

    Parameters:
    -----------
    loss_values : List[float]
        æŸå¤±å€¼åˆ—è¡¨
    """
    # åˆ›å»ºå›¾è¡¨
    plt.figure(figsize=(10, 5))

    # ç”Ÿæˆæ­¥æ•°åˆ—è¡¨
    steps = list(range(1, len(loss_values) + 1))

    # ç»˜åˆ¶æŸå¤±æ›²çº¿
    plt.plot(steps, loss_values, 'b-', linewidth=1.5, alpha=0.8)
    plt.title('Training Loss Curve', fontsize=14, pad=20)
    plt.xlabel('Training Steps')
    plt.ylabel('Loss')
    plt.grid(True, alpha=0.3)

    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    final_loss = loss_values[-1]
    min_loss = min(loss_values)
    max_loss = max(loss_values)
    mean_loss = np.mean(loss_values)

    # åœ¨å›¾è¡¨ä¸Šæ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    stats_text = (f"Final Loss: {final_loss:.4f}\n"
                  f"Min Loss: {min_loss:.4f}\n"
                  f"Mean Loss: {mean_loss:.4f}")

    plt.annotate(stats_text, xy=(0.02, 0.98), xycoords='axes fraction',
                 bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8),
                 verticalalignment='top', fontsize=10)

    plt.tight_layout()

    plt.savefig(pic_path)
    plt.show()

    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print(f"æ€»è®­ç»ƒæ­¥æ•°: {len(loss_values)}")
    print(f"æœ€ç»ˆLoss: {final_loss:.4f}")
    print(f"æœ€å°Loss: {min_loss:.4f}")
    print(f"å¹³å‡Loss: {mean_loss:.4f}")


def fidelity_metric(genereated_images_path, data_path):
    """
    ä½¿ç”¨fidelity packageè®¡ç®—æ‰€æœ‰çš„ç”Ÿæˆç›¸å…³çš„æŒ‡æ ‡ï¼Œè¾“å…¥ç”Ÿæˆå›¾åƒè·¯å¾„å’ŒçœŸå®å›¾åƒè·¯å¾„
    isc: inception score
    kid: kernel inception distance
    fid: frechet inception distance
    """
    metrics_dict = torch_fidelity.calculate_metrics(
        input1=genereated_images_path,
        input2='cifar10-val',
        cuda=True,
        isc=True,
        fid=True,
        kid=True,
        verbose=False,
        datasets_root=data_path
    )
    print(f"Inception Score: {metrics_dict['inception_score_mean']:.4f}")
    print(f"FID: {metrics_dict['frechet_inception_distance']:.4f}")
    print(f"KID: {metrics_dict['kernel_inception_distance_mean']:.4f}")
    return metrics_dict


def generate_images_to_folder(generator, gen_path, z_dim, num_classes, device, total_images=10000):
    """
    ä½¿ç”¨ç”Ÿæˆå™¨ç”ŸæˆæŒ‡å®šæ•°é‡çš„å›¾ç‰‡å¹¶ä¿å­˜åˆ°æ–‡ä»¶å¤¹ï¼Œç”¨äºFIDè®¡ç®—ã€‚

    Args:
        generator: è®­ç»ƒå¥½çš„ç”Ÿæˆå™¨æ¨¡å‹
        gen_path: å›¾ç‰‡ä¿å­˜çš„æ–‡ä»¶å¤¹è·¯å¾„
        total_images: éœ€è¦ç”Ÿæˆçš„æ€»æ•°é‡ (é»˜è®¤ 10000ï¼Œå¯¹åº” CIFAR-10 æµ‹è¯•é›†å¤§å°)
    """
    # 1. åˆ›å»ºç›®å½•
    os.makedirs(gen_path, exist_ok=True)

    # 2. åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼ (å¯¹äº BatchNorm/Dropout å¾ˆé‡è¦)
    generator.eval()

    print(f"ğŸš€ å¼€å§‹ç”Ÿæˆ {total_images} å¼ å›¾åƒåˆ°: {gen_path} ...")

    count = 0
    # ç”Ÿæˆæ—¶çš„ Batch Size å¯ä»¥è®¾ç½®å¤§ä¸€ç‚¹ä»¥æé«˜é€Ÿåº¦ï¼Œåªè¦æ˜¾å­˜å¤Ÿç”¨
    gen_batch_size = 100

    with torch.no_grad():
        while count < total_images:
            # è®¡ç®—å½“å‰æ‰¹æ¬¡éœ€è¦ç”Ÿæˆçš„æ•°é‡ï¼ˆé˜²æ­¢æœ€åä¸€æ¬¡è¶…å‡º total_imagesï¼‰
            current_batch_size = min(gen_batch_size, total_images - count)

            # A. æ„é€ è¾“å…¥
            z = torch.randn(current_batch_size, z_dim).to(device)
            # éšæœºç”Ÿæˆæ ‡ç­¾ (0-9)
            labels = torch.randint(0, num_classes, (current_batch_size,)).to(device)

            # B. ç”Ÿæˆå›¾åƒ
            gen_imgs = generator(z, labels)

            # C. ã€å…³é”®ã€‘åå½’ä¸€åŒ– Denormalization
            # Generator è¾“å‡ºæ˜¯ Tanh [-1, 1]ï¼Œæˆ‘ä»¬éœ€è¦ [0, 1] æ‰èƒ½ä¿å­˜ä¸º PNG
            gen_imgs = (gen_imgs + 1) / 2.0

            # é’³ä½ä»¥é˜²æ•°å€¼æº¢å‡º (å¯é€‰ï¼Œä½†æ¨è)
            gen_imgs.clamp_(0, 1)

            # D. å¾ªç¯ä¿å­˜å½“å‰æ‰¹æ¬¡çš„æ¯ä¸€å¼ å›¾
            for i in range(current_batch_size):
                file_name = f"{count}.png"
                save_path = os.path.join(gen_path, file_name)
                save_image(gen_imgs[i], save_path)
                count += 1

            # æ‰“å°è¿›åº¦æ¡
            sys.stdout.write(f"\rè¿›åº¦: [{count}/{total_images}] ({(count / total_images) * 100:.1f}%)")
            sys.stdout.flush()

    print("\nâœ… ç”Ÿæˆå®Œæ¯•ï¼")


def plot_evaluation_dashboard(loss_values, fid_values, is_mean_values, is_std_values=None, save_path=None):
    """
    ç»˜åˆ¶æ¨¡å‹è¯„ä¼°é¢æ¿ï¼šLoss, Inception Score, FID ä»¥åŠ Loss vs FID ç›¸å…³æ€§ã€‚

    å‚æ•°:
    -----
    loss_values : list or np.array
        æ¯ä¸ª epoch çš„ Training Loss (ä¾‹å¦‚ MSE æˆ– G_Loss)
    fid_values : list or np.array
        æ¯ä¸ª epoch çš„ FID åˆ†æ•°
    is_mean_values : list or np.array
        æ¯ä¸ª epoch çš„ Inception Score å‡å€¼
    is_std_values : list or np.array, optional
        æ¯ä¸ª epoch çš„ Inception Score æ ‡å‡†å·® (é»˜è®¤ä¸º 0)
    save_path : str, optional
        å›¾ç‰‡ä¿å­˜è·¯å¾„ (ä¾‹å¦‚ 'results/metrics.png')ã€‚å¦‚æœä¸ä¼ ï¼Œåˆ™ç›´æ¥æ˜¾ç¤ºã€‚
    """

    # 1. æ•°æ®å‡†å¤‡
    # --- å…³é”®ä¿®æ­£ 1: ç”Ÿæˆä¸¤å¥— X è½´åæ ‡ ---
    # Set A: ç”¨äº Loss (æ€»é•¿åº¦ï¼Œä¾‹å¦‚ 100)
    epochs_loss = np.arange(1, len(loss_values) + 1)

    # Set B: ç”¨äº FID/IS (ç¨€ç–é•¿åº¦ï¼Œä¾‹å¦‚ 10)
    # è®¡ç®—æ­¥é•¿ï¼šä¾‹å¦‚ 100 // 10 = 10
    if len(fid_values) > 0:
        step = len(loss_values) // len(fid_values)
        # ç”Ÿæˆ [10, 20, ..., 100]
        epochs_eval = np.arange(step, len(loss_values) + 1, step)
        # ã€åŒé‡ä¿é™©ã€‘æˆªæ–­å¤šä½™çš„åæ ‡ï¼Œç¡®ä¿ x å’Œ y é•¿åº¦ç»å¯¹ä¸€è‡´
        epochs_eval = epochs_eval[:len(fid_values)]
    else:
        epochs_eval = np.array([])

    if is_std_values is None:
        is_std_values = np.zeros_like(is_mean_values)

    # ç¡®ä¿è¾“å…¥æ˜¯ numpy æ•°ç»„ä»¥ä¾¿ç»˜å›¾
    loss_values = np.array(loss_values)
    fid_values = np.array(fid_values)
    is_mean_values = np.array(is_mean_values)

    # 2. åˆ›å»ºç”»å¸ƒ
    fig, axes = plt.subplots(2, 2, figsize=(20, 10))

    # --- å›¾ 1: Training Loss (å·¦ä¸Š) ---
    ax1 = axes[0, 0]
    ax1.plot(epochs_loss, loss_values, label='Training Loss', color='#377eb8', linewidth=1.5)
    ax1.set_title('Training Loss Over Epochs', fontsize=12, fontweight='bold')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.grid(True, linestyle='--', alpha=0.6)
    ax1.legend()

    # --- å›¾ 2: Inception Score (å³ä¸Š) ---
    ax2 = axes[0, 1]
    # --- å…³é”®ä¿®æ­£ 2: ä½¿ç”¨ epochs_eval (çŸ­) ---
    if len(epochs_eval) == len(is_mean_values):
        ax2.errorbar(epochs_eval, is_mean_values, yerr=is_std_values, fmt='-o',
                     label='Inception Score', color='#377eb8', ecolor='orange',
                     markersize=4, elinewidth=1, capsize=2)
    else:
        print(
            f"âš ï¸ è­¦å‘Š: IS æ•°æ®é•¿åº¦ ({len(is_mean_values)}) ä¸è®¡ç®—å‡ºçš„ Epoch é•¿åº¦ ({len(epochs_eval)}) ä¸åŒ¹é…ï¼Œè·³è¿‡ç»˜å›¾ã€‚")

    ax2.set_title('Inception Score Over Epochs (Higher is Better)', fontsize=12, fontweight='bold')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Inception Score')
    ax2.grid(True, linestyle='--', alpha=0.6)
    ax2.legend()

    # --- å›¾ 3: Frechet Inception Distance (å·¦ä¸‹) ---
    ax3 = axes[1, 0]
    # --- å…³é”®ä¿®æ­£ 3: ä½¿ç”¨ epochs_eval (çŸ­) ---
    if len(epochs_eval) == len(fid_values):
        ax3.plot(epochs_eval, fid_values, label='FID', color='#e41a1c', linewidth=1.5, marker='.')

    ax3.set_title('Frechet Inception Distance Over Epochs (Lower is Better)', fontsize=12, fontweight='bold')
    ax3.set_xlabel('Epoch')
    ax3.set_ylabel('FID')
    ax3.grid(True, linestyle='--', alpha=0.6)
    ax3.legend()

    # --- å›¾ 4: Loss vs FID Correlation (å³ä¸‹) ---
    ax4 = axes[1, 1]
    # ã€æ ¸å¿ƒé€»è¾‘ã€‘å¤„ç†é•¿åº¦ä¸ä¸€è‡´
    if len(loss_values) != len(fid_values):
        # è®¡ç®—æ­¥é•¿ï¼Œä¾‹å¦‚ 100 // 10 = 10
        align_step = len(loss_values) // len(fid_values)

        # å¯¹ Loss è¿›è¡Œåˆ‡ç‰‡ï¼šä»ç¬¬ step-1 ä¸ªå¼€å§‹ï¼Œæ¯éš” step å–ä¸€ä¸ª
        # [:len(fid_values)] æ˜¯ä¸ºäº†é˜²æ­¢é™¤ä¸å°½å¯¼è‡´çš„é•¿åº¦æº¢å‡º
        aligned_loss = loss_values[align_step - 1:: align_step][:len(fid_values)]
    else:
        aligned_loss = loss_values

    # å†æ¬¡æ£€æŸ¥é•¿åº¦ï¼Œé˜²æ­¢ crash
    if len(aligned_loss) == len(fid_values):
        ax4.scatter(aligned_loss, fid_values, label='Loss vs FID', color='#3d8026', alpha=0.8, s=30)

    ax4.set_title('Loss vs FID Correlation', fontsize=12, fontweight='bold')
    ax4.set_xlabel('MSE Loss (Sampled)')
    ax4.set_ylabel('FID')
    ax4.grid(True, linestyle='--', alpha=0.6)
    ax4.legend()

    # 3. å¸ƒå±€è°ƒæ•´ä¸ä¿å­˜
    plt.tight_layout()

    if save_path:
        # è‡ªåŠ¨åˆ›å»ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        directory = os.path.dirname(save_path)
        if directory and not os.path.exists(directory):
            os.makedirs(directory)
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ“Š è¯„ä¼°å›¾è¡¨å·²ä¿å­˜è‡³: {save_path}")
    else:
        plt.show()

    plt.close()  # å…³é—­ç”»å¸ƒé‡Šæ”¾å†…å­˜
