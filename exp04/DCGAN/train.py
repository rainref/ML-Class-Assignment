import os
import sys

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

from config import config, Logger
from model import Generator, Discriminator, weights_init_normal

# ==========================================
# ğŸš‘ã€ä¿®å¤ PyTorch 2.6+ å…¼å®¹æ€§é—®é¢˜çš„è¡¥ä¸ã€‘å¼€å§‹
# ==========================================
# å¼ºåˆ¶è®© torch.load é»˜è®¤ä½¿ç”¨ weights_only=Falseï¼Œæ¢å¤æ—§ç‰ˆæœ¬è¡Œä¸º
_original_torch_load = torch.load


def _safe_torch_load(*args, **kwargs):
    # å¦‚æœè°ƒç”¨æ–¹æ²¡æœ‰æŒ‡å®š weights_onlyï¼Œåˆ™æ‰‹åŠ¨è®¾ç½®ä¸º False
    if 'weights_only' not in kwargs:
        kwargs['weights_only'] = False
    return _original_torch_load(*args, **kwargs)


torch.load = _safe_torch_load
# ==========================================
# ğŸš‘ã€è¡¥ä¸ã€‘ç»“æŸ
# ==========================================
# è·å–å½“å‰è„šæœ¬çš„ç»å¯¹è·¯å¾„ (.../exp04/GAN)
current_dir = os.path.dirname(os.path.abspath(__file__))
# è·å–é¡¹ç›®æ ¹ç›®å½• (å‘ä¸Šé€€ä¸¤çº§: .../exp04/GAN -> .../exp04 -> .../ML-Class-Assignment)
project_root = os.path.abspath(os.path.join(current_dir, "../../"))
# å°†æ ¹ç›®å½•åŠ å…¥ Python æœç´¢è·¯å¾„
sys.path.append(project_root)
from exp04.utils import sample_images, plot_loss_curve, fidelity_metric, generate_images_to_folder, \
    plot_evaluation_dashboard

# --- 1. æ•°æ®åŠ è½½ (é‡ç‚¹ä¿®æ”¹ï¼šå½’ä¸€åŒ–åˆ° -1 ~ 1) ---
transform = transforms.Compose([
    transforms.Resize((config.IMG_SIZE, config.IMG_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  # é‡è¦ï¼
])

train_dataset = datasets.CIFAR10(root=config.DATA_PATH, train=True, download=True, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)

# --- 2. åˆå§‹åŒ–æ¨¡å‹ ---
generator = Generator().to(config.DEVICE)
discriminator = Discriminator().to(config.DEVICE)

# åº”ç”¨æƒé‡åˆå§‹åŒ–
# generator.apply(weights_init_normal)
# discriminator.apply(weights_init_normal)

# --- 3. ä¼˜åŒ–å™¨ä¸æŸå¤±å‡½æ•° ---
adversarial_loss = nn.BCELoss()  # äºŒåˆ†ç±»äº¤å‰ç†µ

optimizer_G = optim.Adam(generator.parameters(), lr=config.LR, betas=(config.BETA1, config.BETA2))
optimizer_D = optim.Adam(discriminator.parameters(), lr=config.LR, betas=(config.BETA1, config.BETA2))


# --- 4. è®­ç»ƒå¾ªç¯ ---
def train():
    print("å¼€å§‹ GAN è®­ç»ƒ...")
    start_epoch = 1
    if config.RESUME_EPOCH > 0:
        print(f"ğŸ”„ æ­£åœ¨åŠ è½½ç¬¬ {config.RESUME_EPOCH} è½®çš„æƒé‡ä»¥æ¥ç»­è®­ç»ƒ...")

        # æ„é€ è·¯å¾„
        g_path = os.path.join(config.CHECKPOINT_PATH, f"generator_epoch_{config.RESUME_EPOCH}.pth")
        d_path = os.path.join(config.CHECKPOINT_PATH, f"discriminator_epoch_{config.RESUME_EPOCH}.pth")
        if os.path.exists(g_path) and os.path.exists(d_path):
            # åŠ è½½å‚æ•° (ä½¿ç”¨ map_location é˜²æ­¢è®¾å¤‡ä¸åŒ¹é…)
            generator.load_state_dict(torch.load(g_path, map_location=config.DEVICE))
            discriminator.load_state_dict(torch.load(d_path, map_location=config.DEVICE))
            print("âœ… æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸï¼")
            start_epoch = config.RESUME_EPOCH + 1
        else:
            print(f"âŒ é”™è¯¯ï¼šåœ¨ {config.CHECKPOINT_PATH} ä¸‹æœªæ‰¾åˆ°ç¬¬ {config.RESUME_EPOCH} è½®çš„æƒé‡æ–‡ä»¶ï¼")
            print("å°†ä»å¤´å¼€å§‹è®­ç»ƒ...")
            # å¦‚æœåŠ è½½å¤±è´¥ï¼Œåº”ç”¨åˆå§‹åŒ–
            generator.apply(weights_init_normal)
            discriminator.apply(weights_init_normal)
    else:
        print("âœ¨ ä»å¤´å¼€å§‹è®­ç»ƒ (éšæœºåˆå§‹åŒ–)...")
        # åªæœ‰åœ¨ä»å¤´è®­ç»ƒæ—¶æ‰åº”ç”¨éšæœºåˆå§‹åŒ–ï¼Œå¦åˆ™ä¼šè¦†ç›–æ‰åŠ è½½çš„æƒé‡
        generator.apply(weights_init_normal)
        discriminator.apply(weights_init_normal)

    print(f"å¼€å§‹ GAN è®­ç»ƒ (ä» Epoch {start_epoch} åˆ° {config.EPOCHS})...")

    g_loss_value = []
    d_loss_value = []
    fid_list = []
    kid_list = []
    is_mean_list = []
    is_std_list = []
    for epoch in range(start_epoch, config.EPOCHS + 1):
        for i, (imgs, labels) in enumerate(train_loader):
            # if i == 0:
            #     print(f"Min: {imgs.min().item()}, Max: {imgs.max().item()}")

            # é…ç½®è¾“å…¥
            batch_size = imgs.shape[0]
            real_imgs = imgs.to(config.DEVICE)
            labels = labels.to(config.DEVICE)

            # å®šä¹‰æ ‡ç­¾ (1: Real, 0: Fake)
            valid = torch.ones(batch_size, 1).to(config.DEVICE)
            fake = torch.zeros(batch_size, 1).to(config.DEVICE)
            valid_smooth = torch.full((batch_size, 1), 0.9).to(config.DEVICE)

            # -----------------
            #  è®­ç»ƒ Generator
            # -----------------
            optimizer_G.zero_grad()

            # é‡‡æ ·å™ªå£°å’Œéšæœºç±»åˆ«
            z = torch.randn(batch_size, config.Z_DIM).to(config.DEVICE)
            gen_labels = torch.randint(0, config.NUM_CLASSES, (batch_size,)).to(config.DEVICE)

            # ç”Ÿæˆå›¾ç‰‡
            gen_imgs = generator(z, gen_labels)

            # Loss: å¸Œæœ› Discriminator è®¤ä¸ºè¿™äº›ç”Ÿæˆçš„å›¾ç‰‡æ˜¯ Valid (1)
            # D(G(z)) -> 1
            g_loss = adversarial_loss(discriminator(gen_imgs, gen_labels), valid)

            g_loss.backward()
            optimizer_G.step()

            # ---------------------
            #  è®­ç»ƒ Discriminator
            # ---------------------
            optimizer_D.zero_grad()

            # 1. çœŸå®å›¾ç‰‡ Loss
            real_pred = discriminator(real_imgs, labels)
            d_real_loss = adversarial_loss(real_pred, valid_smooth)

            # 2. ç”Ÿæˆå›¾ç‰‡ Loss (ä½¿ç”¨ .detach() é˜²æ­¢æ¢¯åº¦ä¼ å› G)
            fake_pred = discriminator(gen_imgs.detach(), gen_labels)
            d_fake_loss = adversarial_loss(fake_pred, fake)

            # æ€» D Loss
            d_loss = (d_real_loss + d_fake_loss) / 2

            d_loss.backward()
            optimizer_D.step()

            if i % 100 == 0:
                print(f"[Epoch {epoch}/{config.EPOCHS}] [Batch {i}/{len(train_loader)}] "
                      f"[D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]")
            is_last_batch = (i == len(train_loader) - 1)
            if is_last_batch:
                g_loss_value.append(g_loss.item())
                d_loss_value.append(d_loss.item())
        # --- æ¯ä¸ª Epoch ç»“æŸåçš„å¯è§†åŒ– ---
        sample_images(epoch, generator, config.NUM_CLASSES, config.DEVICE, config.RESULTS_PATH, config.Z_DIM)
        print(f"æ­£åœ¨è¯„ä¼°ç¬¬ {epoch} è½®...")
        # A. å…ˆç”Ÿæˆå›¾ç‰‡ä¿å­˜åˆ°æ–‡ä»¶å¤¹
        gen_path = os.path.join(config.OUTPUT_DIR, f"eval_epoch_{epoch}")
        generate_images_to_folder(generator, gen_path, config.Z_DIM, config.NUM_CLASSES, config.DEVICE)
        generator.train()

        # B. è°ƒç”¨ä½ çš„è¯„ä¼°å‡½æ•°
        metrics = fidelity_metric(gen_path, config.DATA_PATH)

        # C. ã€æ ¸å¿ƒã€‘æå–å‚æ•°å¹¶å­˜å…¥åˆ—è¡¨
        fid_list.append(metrics['frechet_inception_distance'])
        kid_list.append(metrics['kernel_inception_distance_mean'])
        is_mean_list.append(metrics['inception_score_mean'])
        is_std_list.append(metrics['inception_score_std'])  # è¿™é‡Œæ‹¿åˆ°äº† std

        # ä¿å­˜æ¨¡å‹
        if epoch % 10 == 0:
            torch.save(generator.state_dict(), os.path.join(config.CHECKPOINT_PATH, f"generator_epoch_{epoch}.pth"))
            torch.save(discriminator.state_dict(),
                       os.path.join(config.CHECKPOINT_PATH, f"discriminator_epoch_{epoch}.pth"))

    print("è®­ç»ƒç»“æŸï¼Œæ­£åœ¨ç»˜å›¾...")
    # å°†å…¶å­˜å…¥æ—¥å¿—æ–‡ä»¶ï¼Œæ‰“å°è¿™äº›å€¼
    print('g_loss_value:', g_loss_value)
    print('d_loss_value:', d_loss_value)
    print('fid_list:', fid_list)
    print('kid_list:', kid_list)
    print('is_mean_list:', is_mean_list)
    print('is_std_list:', is_std_list)
    plot_evaluation_dashboard(
        loss_values=g_loss_value,
        fid_values=fid_list,
        is_mean_values=is_mean_list,  # å¯¹åº”å‚æ•° 1
        is_std_values=is_std_list,  # å¯¹åº”å‚æ•° 2
        save_path='./final_evaluation.png'
    )
    plot_loss_curve(g_loss_value, './g_loss_curve.png')
    plot_loss_curve(d_loss_value, './d_loss_curve.png')


if __name__ == "__main__":
    sys.stdout = Logger("training_log.txt")
    train()
